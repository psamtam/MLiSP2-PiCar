{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 17:52:36.061194: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-12 17:52:36.091935: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-12 17:52:36.091960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-12 17:52:36.092688: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 17:52:36.098730: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-12 17:52:36.655436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.__version__: 2.2.3\n",
      "tf.__version__: 2.15.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Model\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from custom_class import *\n",
    "\n",
    "print(f\"pd.__version__: {pd.__version__}\")\n",
    "print(f\"tf.__version__: {tf.__version__}\")\n",
    "\n",
    "image_shape = (60, 80, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_heads = []\n",
    "angle_heads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_weight_paths = [\n",
    "    \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/auto_pilot/Models/angle_model_60x80_20250311_2005/angle_model_60x80_20250311_2005.weights.h5\",\n",
    "    \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/auto_pilot/Models/angle_model_60x80_20250311_2013/angle_model_60x80_20250311_2013.weights.h5\",\n",
    "]\n",
    "\n",
    "speed_weight_paths = [\n",
    "    \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/auto_pilot/Models/speed_model_60x80_20250311_2024/speed_model_20250311_2024.weights.h5\",\n",
    "    \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/auto_pilot/Models/speed_model_60x80_20250311_2052/speed_model_60x80_20250311_2052.weights.h5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_heads_angle = [\n",
    "    [5, 6, 7],\n",
    "    [0, 1],\n",
    "]\n",
    "\n",
    "needed_heads_speed = [\n",
    "    [1, 6, 8],\n",
    "    [1, 3],\n",
    "]\n",
    "\n",
    "total_num_of_heads = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 17:52:38.324806: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.350719: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.350761: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.353493: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.353529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.353547: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.464354: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.464421: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.464428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-12 17:52:38.464460: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-12 17:52:38.464478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5582 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "mobilenetv3 = keras.applications.MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "\n",
    "backbone = Model(inputs=mobilenetv3.input, outputs=mobilenetv3.get_layer(\"expanded_conv_14/Add\").output, name=\"MobileNetV3Large_backbone\")\n",
    "neck = Model(inputs=mobilenetv3.get_layer(\"expanded_conv_14/Add\").output, outputs=mobilenetv3.output, name=\"MobileNetV3Large_neck\")\n",
    "neck_out = neck(backbone.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Angle model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "(None, 2, 3, 960)\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "\n",
    "feature_extractor = base_model.output\n",
    "\n",
    "print(feature_extractor.shape)\n",
    "\n",
    "a_model = []\n",
    "\n",
    "output_activation_1 = 'sigmoid'\n",
    "output_activation_2 = 'linear'\n",
    "\n",
    "\n",
    "# model 0\n",
    "i = 0\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(128, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_2')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_2')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_2')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 1\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(496, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_2')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_2')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_2')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 2\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "a = layers.Conv2D(128, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "a = layers.Dense(384, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(96, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 3\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(72, (3, 3), (2, 2), padding='same', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.4, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.1, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 4\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "\n",
    "# Conv to reduce channels\n",
    "a = layers.Conv2D(64, (3, 3), padding='same', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "\n",
    "# Dense layers\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# model 5\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "\n",
    "# Conv to reduce channels\n",
    "a = layers.Conv2D(64, (3, 3), padding='same', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "\n",
    "# Dense layers\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 6\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# model 7\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(468, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(64, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 8\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "a = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_attention_flatten')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(64, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# model 9\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(86, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(168, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "outputs_dict = {}\n",
    "\n",
    "for i in range(len(a_model)):\n",
    "    outputs_dict[f'angle{i}_output'] = a_model[i]\n",
    "\n",
    "\n",
    "angle_model = Model(inputs=base_model.input, outputs=outputs_dict, name=\"angle_model\")\n",
    "\n",
    "angle_model.load_weights(angle_weight_paths[len(angle_heads)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed = []\n",
    "for i in needed_heads_angle[len(angle_heads)]:\n",
    "    needed.append(angle_model.outputs[i])\n",
    "\n",
    "angle_heads.append(Model(inputs=base_model.get_layer(\"expanded_conv_14/Add\").output, outputs=needed, name=f\"angle_head_{len(angle_heads)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Angle model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "(None, 2, 3, 960)\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "\n",
    "feature_extractor = base_model.output\n",
    "\n",
    "print(feature_extractor.shape)\n",
    "\n",
    "a_model = []\n",
    "\n",
    "output_activation_1 = 'sigmoid'\n",
    "output_activation_2 = 'linear'\n",
    "\n",
    "\n",
    "# model 0\n",
    "i = 0\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(128, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_2')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_2')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_2')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 1\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(496, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_2')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_2')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_2')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 2\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "a = layers.Conv2D(128, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "a = layers.Dense(384, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(96, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 3\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(72, (3, 3), (2, 2), padding='same', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.4, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.1, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 4\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "\n",
    "# Conv to reduce channels\n",
    "a = layers.Conv2D(64, (3, 3), padding='same', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "\n",
    "# Dense layers\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# model 5\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "\n",
    "# Conv to reduce channels\n",
    "a = layers.Conv2D(64, (3, 3), padding='same', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "\n",
    "# Dense layers\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 6\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# model 7\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(468, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(64, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "# model 8\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "a = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.Flatten(name=f'a{i}_attention_flatten')(a)\n",
    "a = layers.Dense(512, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(64, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# model 9\n",
    "i += 1\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(86, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(a)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"sigmoid\", name=f'a{i}_attention_conv')(a)\n",
    "a = layers.Multiply(name=f'a{i}_attention_apply')([a, a_attention])\n",
    "a = layers.Flatten(name=f'a{i}_flatten')(a)\n",
    "a = layers.Dense(168, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "a = layers.Dense(1, activation=output_activation_1, name=f'a{i}_output')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "outputs_dict = {}\n",
    "\n",
    "for i in range(len(a_model)):\n",
    "    outputs_dict[f'angle{i}_output'] = a_model[i]\n",
    "\n",
    "\n",
    "angle_model = Model(inputs=base_model.input, outputs=outputs_dict, name=\"angle_model\")\n",
    "\n",
    "angle_model.load_weights(angle_weight_paths[len(angle_heads)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed = []\n",
    "for i in needed_heads_angle[len(angle_heads)]:\n",
    "    needed.append(angle_model.outputs[i])\n",
    "\n",
    "angle_heads.append(Model(inputs=base_model.get_layer(\"expanded_conv_14/Add\").output, outputs=needed, name=f\"angle_head_{len(angle_heads)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge angle heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'angle_head_0')>,\n",
       "  <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'angle_head_0')>,\n",
       "  <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'angle_head_0')>],\n",
       " [<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'angle_head_1')>,\n",
       "  <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'angle_head_1')>]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_heads_out = [angle_head(backbone.output) for angle_head in angle_heads]\n",
    "angle_heads_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle_head = Model(inputs=base_model.get_layer(\"expanded_conv_14/Add\").output, outputs=angle_model.output, name=\"angle_head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "(None, 2, 3, 960)\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "\n",
    "feature_extractor = base_model.output\n",
    "\n",
    "print(feature_extractor.shape)\n",
    "\n",
    "s_model = []\n",
    "\n",
    "output_activation_1 = 'sigmoid'\n",
    "output_activation_2 = 'linear'\n",
    "\n",
    "\n",
    "# model 0\n",
    "i = 0\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_2')(feature_extractor)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_2')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_2')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "s = layers.Dense(196, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 1\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(256, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(feature_extractor)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_2')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_2')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_2')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 2\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"relu\", name=f's{i}_attention_conv')(s)\n",
    "s = layers.Multiply(name=f's{i}_attention_apply')([s, s_attention])\n",
    "s = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "s = layers.Dense(312, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(96, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 3\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(64, (3, 3), (2, 2), padding='same', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(36, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(24, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.4, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 4\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "\n",
    "# Conv to reduce channels\n",
    "s = layers.Conv2D(64, (3, 3), padding='same', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "\n",
    "# Dense layers\n",
    "s = layers.Dense(52, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.4, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "\n",
    "# model 5\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "\n",
    "# Conv to reduce channels\n",
    "s = layers.Conv2D(64, (3, 3), padding='same', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "\n",
    "# Dense layers\n",
    "s = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 6\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(72, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "\n",
    "# model 7\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(48, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(52, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 8\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"relu\", name=f's{i}_attention_conv')(s)\n",
    "s = layers.Multiply(name=f's{i}_attention_apply')([s, s_attention])\n",
    "s = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_2')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_2')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_2')(s)\n",
    "s = layers.Conv2D(32, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_attention_flatten')(s)\n",
    "s = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "\n",
    "# model 9\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(48, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"relu\", name=f's{i}_attention_conv')(s)\n",
    "s = layers.Multiply(name=f's{i}_attention_apply')([s, s_attention])\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(48, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(28, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.4, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "outputs_dict = {}\n",
    "\n",
    "\n",
    "for i in range(len(s_model)):\n",
    "    outputs_dict[f'speed{i}_output'] = s_model[i]\n",
    "\n",
    "\n",
    "speed_model = Model(inputs=base_model.input, outputs=outputs_dict, name=\"speed_model\")\n",
    "\n",
    "speed_model.load_weights(speed_weight_paths[len(speed_heads)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed = []\n",
    "for i in needed_heads_speed[len(speed_heads)]:\n",
    "  needed.append(speed_model.outputs[i])\n",
    "\n",
    "speed_heads.append(Model(inputs=base_model.output, outputs=needed, name=f\"speed_head_{len(speed_heads)}\"))\n",
    "# speed_head = Model(inputs=base_model.output, outputs=speed_model.output, name=\"speed_head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speed model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n",
      "(None, 2, 3, 960)\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV3Large(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "\n",
    "feature_extractor = base_model.output\n",
    "\n",
    "print(feature_extractor.shape)\n",
    "\n",
    "s_model = []\n",
    "\n",
    "output_activation_1 = 'sigmoid'\n",
    "output_activation_2 = 'linear'\n",
    "\n",
    "\n",
    "# model 0\n",
    "i = 0\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_2')(feature_extractor)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_2')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_2')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "s = layers.Dense(196, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 1\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(256, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(feature_extractor)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_2')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_2')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_2')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 2\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"relu\", name=f's{i}_attention_conv')(s)\n",
    "s = layers.Multiply(name=f's{i}_attention_apply')([s, s_attention])\n",
    "s = layers.Conv2D(96, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "s = layers.Dense(312, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(96, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 3\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(64, (3, 3), (2, 2), padding='same', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(36, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(24, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.4, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 4\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "\n",
    "# Conv to reduce channels\n",
    "s = layers.Conv2D(64, (3, 3), padding='same', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "\n",
    "# Dense layers\n",
    "s = layers.Dense(52, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.4, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "\n",
    "# model 5\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "\n",
    "# Conv to reduce channels\n",
    "s = layers.Conv2D(64, (3, 3), padding='same', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.GlobalAveragePooling2D(name=f's{i}_GAP')(s)\n",
    "\n",
    "# Dense layers\n",
    "s = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 6\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(72, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "\n",
    "# model 7\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(48, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(52, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "# model 8\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"relu\", name=f's{i}_attention_conv')(s)\n",
    "s = layers.Multiply(name=f's{i}_attention_apply')([s, s_attention])\n",
    "s = layers.Conv2D(64, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_2')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_2')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_2')(s)\n",
    "s = layers.Conv2D(32, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s = layers.Flatten(name=f's{i}_attention_flatten')(s)\n",
    "s = layers.Dense(32, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "\n",
    "# model 9\n",
    "i += 1\n",
    "\n",
    "s = feature_extractor\n",
    "s = layers.Conv2D(48, (3, 3), (2, 2), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f's{i}_conv_1')(s)\n",
    "s = layers.BatchNormalization(name=f's{i}_bn_1')(s)\n",
    "s = layers.Activation('relu', name=f's{i}_relu_1')(s)\n",
    "s_attention = layers.Conv2D(1, (1, 1), padding='same', activation=\"relu\", name=f's{i}_attention_conv')(s)\n",
    "s = layers.Multiply(name=f's{i}_attention_apply')([s, s_attention])\n",
    "s = layers.Flatten(name=f's{i}_flatten')(s)\n",
    "s = layers.Dense(48, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_2')(s)\n",
    "s = layers.Dropout(0.5, name=f's{i}_dropout_2')(s)\n",
    "s = layers.Dense(28, activation='relu', kernel_initializer='he_uniform', name=f's{i}_dense_1')(s)\n",
    "s = layers.Dropout(0.4, name=f's{i}_dropout')(s)\n",
    "s = layers.Dense(1, activation=output_activation_1, name=f's{i}_output')(s)\n",
    "\n",
    "s_model.append(s)\n",
    "\n",
    "\n",
    "outputs_dict = {}\n",
    "\n",
    "\n",
    "for i in range(len(s_model)):\n",
    "    outputs_dict[f'speed{i}_output'] = s_model[i]\n",
    "\n",
    "\n",
    "speed_model = Model(inputs=base_model.input, outputs=outputs_dict, name=\"speed_model\")\n",
    "\n",
    "speed_model.load_weights(speed_weight_paths[len(speed_heads)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed = []\n",
    "for i in needed_heads_speed[len(speed_heads)]:\n",
    "  needed.append(speed_model.outputs[i])\n",
    "\n",
    "speed_heads.append(Model(inputs=base_model.output, outputs=needed, name=f\"speed_head_{len(speed_heads)}\"))\n",
    "# speed_head = Model(inputs=base_model.output, outputs=speed_model.output, name=\"speed_head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge speed heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'speed_head_0')>,\n",
       "  <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'speed_head_0')>,\n",
       "  <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'speed_head_0')>],\n",
       " [<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'speed_head_1')>,\n",
       "  <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'speed_head_1')>]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed_heads_out = [speed_head(neck_out) for speed_head in speed_heads]\n",
    "speed_heads_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_model = Model(inputs=backbone.input, outputs=speed_heads_out, name=\"merged_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = Model(inputs=backbone.input, outputs=angle_heads_out + speed_heads_out, name=\"merged_model\")\n",
    "# merged_model = Model(inputs=backbone.input, outputs=[angle_head(backbone.output)] + speed_heads_out, name=\"merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(\n",
    "#     merged_model,\n",
    "#     show_shapes=True,  # Show input/output shapes\n",
    "#     show_layer_names=True,  # Show layer names (e.g., \"angle_hidden_2\")\n",
    "#     expand_nested=False,  # Keep it flat (no base_model nesting)\n",
    "#     show_layer_activations=True,\n",
    "#     dpi=96,  # Image resolution\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Dataset/machine-learning-in-science-ii-2025/test_data/test_data/1.png'\n",
      "b'Dataset/machine-learning-in-science-ii-2025/test_data/test_data/10.png'\n",
      "b'Dataset/machine-learning-in-science-ii-2025/test_data/test_data/100.png'\n",
      "b'Dataset/machine-learning-in-science-ii-2025/test_data/test_data/1000.png'\n",
      "b'Dataset/machine-learning-in-science-ii-2025/test_data/test_data/1001.png'\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"Dataset/machine-learning-in-science-ii-2025/test_data/test_data\"\n",
    "\n",
    "ds = tf.data.Dataset.list_files(\n",
    "    os.path.join(dataset_dir, \"*\"), shuffle=False\n",
    ")\n",
    "image_count = len(ds)\n",
    "\n",
    "for f in ds.take(5):\n",
    "    print(f.numpy())\n",
    "\n",
    "# Extract image IDs\n",
    "def extract_image_id(file_path):\n",
    "    file_path = file_path.numpy().decode(\"utf-8\")  # Convert from bytes to string\n",
    "    filename = os.path.basename(file_path)  # Extract \"1.png\", \"10.png\", etc.\n",
    "    image_id = filename.split(\".\")[0]  # Extract \"1\", \"10\", \"100\"\n",
    "    return image_id\n",
    "\n",
    "image_id_list = []\n",
    "\n",
    "for path in ds:\n",
    "    image_id_list.append(extract_image_id(path))\n",
    "\n",
    "image_id_list = np.array(image_id_list)\n",
    "\n",
    "def decode_img(img):\n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "def process_path(file_path):\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img\n",
    "\n",
    "ds = ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def scale_ds(image):\n",
    "    # Range of input image: [0, 1]\n",
    "    return image * 2 - 1.0\n",
    "\n",
    "ds = ds.map(scale_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def resize_ds(image):\n",
    "    return tf.image.resize(image, [image_shape[0], image_shape[1]])\n",
    "\n",
    "ds = ds.map(resize_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.batch(1, drop_remainder=False)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "ds = configure_for_performance(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = merged_model.predict(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle_preds = preds[0:2]\n",
    "# angle_preds_list = []\n",
    "\n",
    "# for angle_pred in angle_preds:\n",
    "#     for ap in angle_pred:\n",
    "#         angle_preds_list.append(ap[:, 0])\n",
    "\n",
    "# angle_preds_list = np.array(angle_preds_list)\n",
    "\n",
    "# angle_preds_list = np.where(np.abs(angle_preds_list - 0.5) < 0.1, angle_preds_list, (angle_preds_list - 0.5) * 1.1 + 0.5)\n",
    "\n",
    "# angle_pred = np.mean(angle_preds_list, axis=0)\n",
    " \n",
    "# print(angle_pred)\n",
    "\n",
    "# angle_pred_df = pd.DataFrame({\"image_id\": image_id_list.astype(int), \"angle\": angle_pred}).set_index('image_id')\n",
    "# # angle_pred_df.sort_index().to_csv(\"test_angle_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed_preds = preds[2:]\n",
    "# speed_preds_list = []\n",
    "\n",
    "# for speed_pred in speed_preds:\n",
    "#     for sp in speed_pred:\n",
    "#         speed_preds_list.append(sp[:, 0])\n",
    "\n",
    "\n",
    "# # speed_preds_list = []\n",
    "# # for speed_pred in speed_preds:\n",
    "# #     speed_preds_list.append(speed_pred[0][:, 0])\n",
    "# #     speed_preds_list.append(speed_pred[1][:, 0])\n",
    "\n",
    "# # speed_preds = np.mean(speed_preds_list, axis=0)\n",
    "# # speed_preds[0][0]\n",
    "\n",
    "# speed_preds_list = np.array(speed_preds_list)\n",
    "\n",
    "# speed_preds_list.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model into TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfquo_5wq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpfquo_5wq/assets\n",
      "2025-03-12 17:53:11.555988: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-03-12 17:53:11.556044: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-03-12 17:53:11.557131: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpfquo_5wq\n",
      "2025-03-12 17:53:11.588373: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-03-12 17:53:11.588407: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpfquo_5wq\n",
      "2025-03-12 17:53:11.656696: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2025-03-12 17:53:11.691836: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-03-12 17:53:12.278928: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpfquo_5wq\n",
      "2025-03-12 17:53:12.494452: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 937325 microseconds.\n",
      "2025-03-12 17:53:12.721775: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 130, Total Ops 399, % non-converted = 32.58 %\n",
      " * 130 ARITH ops\n",
      "\n",
      "- arith.constant:  130 occurrences  (f32: 120, i32: 10)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 10)\n",
      "  (f32: 62)\n",
      "  (f32: 15)\n",
      "  (f32: 25)\n",
      "  (f32: 20)\n",
      "  (f32: 10)\n",
      "  (f32: 10)\n",
      "  (f32: 17)\n",
      "  (f32: 4)\n",
      "  (uq_8: 85)\n",
      "  (f32: 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model: merged_model_60x80.tflite saved successfully!\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(merged_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Enable optimization\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tf_lite_file_name = f\"merged_model_{image_shape[0]}x{image_shape[1]}_{total_num_of_heads}heads.tflite\"\n",
    "\n",
    "with open(tf_lite_file_name, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model: merged_model_{image_shape[0]}x{image_shape[1]}.tflite saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.lite as tflite  # Use this if full TensorFlow is installed\n",
    "# If using tflite-runtime, import this instead:\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tflite.Interpreter(model_path=tf_lite_file_name)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Create a dummy input (modify based on model input shape)\n",
    "input_data = \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/Dataset/machine-learning-in-science-ii-2025/test_data/test_data/1.png\"\n",
    "input_data = np.array(Image.open(input_data).convert('RGB').resize((image_shape[1], image_shape[0])))\n",
    "\n",
    "# convert to range(-1, 1)\n",
    "input_data = input_data / 255 * 2 - 1\n",
    "\n",
    "input_data = input_data.astype(np.float32)\n",
    "\n",
    "input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_details = interpreter.get_output_details()\n",
    "# output_dict = {o['name']: o['index'] for o in output_details}\n",
    "\n",
    "# angle_outputs = [interpreter.get_tensor(output_dict[f'StatefulPartitionedCall:{i}']) for i in range(10)]\n",
    "# speed_outputs = [interpreter.get_tensor(output_dict[f'StatefulPartitionedCall:{i}']) for i in range(10, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9299/1716235872.py:9: RuntimeWarning: Mean of empty slice.\n",
      "  angle_outputs.mean(), speed_outputs.mean()\n",
      "/home/ubuntu/miniconda3/envs/mlis2/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28291252, nan)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details_sorted = sorted(output_details, key=lambda x: int(x['name'].split(':')[-1]))\n",
    "\n",
    "all_outputs = [interpreter.get_tensor(out['index']) for out in output_details_sorted]\n",
    "\n",
    "# Split into angle_outputs (0-9) and speed_outputs (10-19)\n",
    "angle_outputs = np.array(all_outputs[:10])\n",
    "speed_outputs = np.array(all_outputs[10:])\n",
    "\n",
    "angle_outputs.mean(), speed_outputs.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
