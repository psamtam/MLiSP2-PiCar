{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Model\n",
    "import keras as k\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from custom_class import *\n",
    "\n",
    "print(f\"pd.__version__: {pd.__version__}\")\n",
    "print(f\"tf.__version__: {tf.__version__}\")\n",
    "\n",
    "image_size = (120, 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file path and labels to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/Captured_data/processed\"\n",
    "\n",
    "dataset_dir_list = [\n",
    "    os.path.join(dataset_dir, folder)\n",
    "    for folder in os.listdir(dataset_dir)\n",
    "    if os.path.isdir(os.path.join(dataset_dir, folder))\n",
    "]\n",
    "\n",
    "csv_path_list = [os.path.join(dir, \"_labels.csv\") for dir in dataset_dir_list]\n",
    "\n",
    "csv_df = None\n",
    "\n",
    "for csv_path in csv_path_list:\n",
    "    df = pd.read_csv(csv_path, index_col=\"image_id\")\n",
    "    if \"_red\" in csv_path or \"_obj\" in csv_path:\n",
    "        continue\n",
    "    # undersampling\n",
    "    elif \"oval\" in csv_path:\n",
    "        df = df.sample(frac=1.0, random_state=42)\n",
    "    # oversampling\n",
    "    elif \"T_\" in csv_path:\n",
    "        df = df.sample(frac=1, replace=True, random_state=42)\n",
    "    df.index = csv_path.split(\"/\")[-2] + \"/\" + df.index\n",
    "    csv_df = pd.concat([csv_df, df])\n",
    "\n",
    "csv_df = csv_df[[\"angle\", \"left_arrow\", \"right_arrow\"]]\n",
    "\n",
    "display(csv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter arrow labels\n",
    "\n",
    "csv_df[\"left_arrow_turn\"] = ((np.abs(csv_df['angle'] - 0.5) > 0.1) & (csv_df[\"left_arrow\"] == 1)).astype(int)\n",
    "csv_df[\"right_arrow_turn\"] = ((np.abs(csv_df['angle'] - 0.5) > 0.15) & (csv_df[\"right_arrow\"] == 1)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling left and right arrow\n",
    "df1 = csv_df[(csv_df[\"left_arrow\"] == 0.0)]\n",
    "df2 = csv_df[~csv_df.index.isin(df1.index)]\n",
    "df2 = df2.sample(frac=1.15, replace=True, random_state=42)\n",
    "csv_df = pd.concat([df1, df2])\n",
    "\n",
    "df1 = csv_df[(csv_df[\"right_arrow\"] == 0.0)]\n",
    "df2 = csv_df[~csv_df.index.isin(df1.index)]\n",
    "df2 = df2.sample(frac=2.0, replace=True, random_state=42)\n",
    "csv_df = pd.concat([df1, df2])\n",
    "\n",
    "csv_df = csv_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = csv_df[(csv_df[\"angle\"] == 0.5) & (csv_df[\"left_arrow\"] == 0.0) & (csv_df[\"right_arrow\"] == 0.0)]\n",
    "df2 = csv_df[~csv_df.index.isin(df1.index)]\n",
    "df1 = df1.sample(frac=0.5, random_state=42)\n",
    "new_df = pd.concat([df1, df2])\n",
    "new_df = new_df.sample(frac=1, random_state=42)\n",
    "\n",
    "df1 = new_df[(new_df[\"left_arrow\"] == 0.0) & (new_df[\"right_arrow\"] == 0.0)]\n",
    "df2 = new_df[~new_df.index.isin(df1.index)]\n",
    "df1 = df1.sample(frac=1.0, random_state=42)\n",
    "new_df = pd.concat([df1, df2])\n",
    "new_df = new_df.sample(frac=1, random_state=42)\n",
    "\n",
    "csv_df = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "ax = ax.ravel()\n",
    "\n",
    "print(ax[0].hist(csv_df[\"left_arrow\"]))\n",
    "print(ax[1].hist(csv_df[\"right_arrow\"]))\n",
    "print(ax[2].hist(csv_df[\"left_arrow_turn\"]))\n",
    "print(ax[3].hist(csv_df[\"right_arrow_turn\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = csv_df[\"angle\"]\n",
    "\n",
    "df = pd.DataFrame(angle)\n",
    "bins = np.unique(angle)\n",
    "c = df[\"angle\"].value_counts()\n",
    "\n",
    "angle_count = {}\n",
    "\n",
    "for bin in bins:\n",
    "    angle_count[bin] = c[bin]\n",
    "\n",
    "key, value = list(angle_count.keys()), list(angle_count.values())\n",
    "\n",
    "for i in range(len(key)):\n",
    "    print(f\"{key[i]:.5f} {value[i]}\")\n",
    "\n",
    "print(angle_count)\n",
    "\n",
    "plt.bar(key, value, width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 5695\n",
    "X = np.array(csv_df.index)\n",
    "y = np.array(csv_df)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.15, random_state=rs\n",
    "# )\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=(0.15 / 0.85), random_state=rs\n",
    "# )\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y_trian_left:{sum(y_train[:, 1] == 1) / len(y_train):.4f}, y_trian_right:{sum(y_train[:, 2] == 1) / len(y_train):.4f}\")\n",
    "print(f\"y_val_left:{sum(y_val[:, 1] == 1) / len(y_val):.4f}, y_val_right:{sum(y_val[:, 2] == 1) / len(y_val):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_path = [\n",
    "    os.path.join(dataset_dir, str(image_id) + \".png\") for image_id in X_train\n",
    "]\n",
    "X_val_path = [os.path.join(dataset_dir, str(image_id) + \".png\") for image_id in X_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(\n",
    "    img,\n",
    "):  # -> Any | defaultdict | Any | list | None | object | Tensor | ...:\n",
    "    # Convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.io.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_path(file_path, labels):\n",
    "    # Load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, labels\n",
    "\n",
    "\n",
    "def image_id_to_path(image_id, labels):\n",
    "    image_path = tf.strings.join(\n",
    "        [dataset_dir, \"/\", tf.as_string(image_id), \".png\"]\n",
    "    )  # Assuming images are .jpg\n",
    "    return image_path, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train_path, y_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val_path, y_val))\n",
    "\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds_length = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "print(train_ds_length)\n",
    "val_ds_length = tf.data.experimental.cardinality(val_ds).numpy()\n",
    "print(val_ds_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "i = 0\n",
    "\n",
    "for image, labels in train_ds.take(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image.numpy().astype(\"float32\"))\n",
    "    labels = labels.numpy()\n",
    "    plt.title(f\"angle: {labels}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(original, augmented):\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original image\")\n",
    "    plt.imshow(original.numpy().astype(\"float32\"))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Augmented image\")\n",
    "    plt.imshow(augmented.numpy().astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_by_degree = 5\n",
    "random_rotate = keras.layers.RandomRotation(rotate_by_degree / 360)\n",
    "\n",
    "\n",
    "def augment(image, labels, seed=None):\n",
    "    # Deal with the random seed\n",
    "    if seed == None:\n",
    "        seed = tf.random.uniform(shape=[2], maxval=10000, dtype=tf.int32)\n",
    "    else:\n",
    "        seed = tf.constant([seed, seed], dtype=tf.int32)\n",
    "\n",
    "    image = tf.image.stateless_random_brightness(image, 0.3, seed)\n",
    "    image = tf.image.stateless_random_contrast(image, 0.75, 1.25, seed)\n",
    "    image = tf.image.stateless_random_hue(image, 0.05, seed)\n",
    "    image = tf.image.stateless_random_saturation(image, 0.7, 1.2, seed)\n",
    "    image = tf.image.stateless_random_jpeg_quality(image, 80, 100, seed)\n",
    "\n",
    "    image = random_rotate(image)\n",
    "\n",
    "    # crop image\n",
    "    image = tf.image.stateless_random_crop(image, size=[210, 280, 3], seed=seed)\n",
    "\n",
    "    # resize image back to 240x320\n",
    "    image = tf.image.resize(image, [240, 320])\n",
    "\n",
    "    return image, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test augment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 20\n",
    "# skip+=1\n",
    "print(skip)\n",
    "for i in range(3):\n",
    "    for image, angle in train_ds.skip(skip).take(1):\n",
    "        augmented_image, angle = augment(image, angle, None)\n",
    "        visualise(image, augmented_image)\n",
    "\n",
    "for image, angle in train_ds.take(1):\n",
    "    aug_image, aug_angle = augment(image, angle)\n",
    "    print(f\"Augmented image shape: {aug_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_ds(image, labels):\n",
    "    # Range of input image: [0, 1]\n",
    "    return image * 2 - 1.0, labels       # [-1, 1]\n",
    "    # return image * 255, labels               # [0, 255]\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(scale_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(scale_ds, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_ds(image, labels):\n",
    "    return tf.image.resize(image, [image_size[0], image_size[1]]), labels\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(resize_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(resize_ds, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, labels in train_ds.take(1):\n",
    "    print(image.shape)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rephrase_ds(image, labels):\n",
    "    # return image, {\"angle_output\": angle}\n",
    "    # angle_dict = {}\n",
    "    # for i in range(10):\n",
    "    #     angle_dict[f\"angle{i}_output\"] = angle\n",
    "\n",
    "    # return image, {\"angle\": labels[0], \"left_arrow\": labels[1], \"right_arrow\": labels[2]}\n",
    "    return image, {\"angle\": labels[0], \"left_arrow\": labels[1], \"right_arrow\": labels[2], \"left_arrow_turn\": labels[3], \"right_arrow_turn\": labels[4]}\n",
    "\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(rephrase_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(rephrase_ds, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "\n",
    "\n",
    "def configure_for_performance(ds, shuffle: bool, batch: bool):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "    if batch:\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        ds = ds.batch(1, drop_remainder=False)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = train_ds.repeat()\n",
    "val_ds = val_ds.repeat()\n",
    "train_ds = configure_for_performance(train_ds, shuffle=True, batch=True)\n",
    "val_ds = configure_for_performance(val_ds, shuffle=False, batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_sample = y_train.shape[0]\n",
    "\n",
    "# left\n",
    "num_positive = np.sum(y_train[:, 1])\n",
    "weight_positive = total_train_sample / (2 * num_positive)  # Divide by 2 for balance\n",
    "weight_negative = total_train_sample / (2 * (total_train_sample - num_positive))\n",
    "left_weight = {0: weight_negative, 1: weight_positive}\n",
    "\n",
    "# right\n",
    "num_positive = np.sum(y_train[:, 2])\n",
    "weight_positive = total_train_sample / (2 * num_positive)  # Divide by 2 for balance\n",
    "weight_negative = total_train_sample / (2 * (total_train_sample - num_positive))\n",
    "right_weight = {0: weight_negative, 1: weight_positive}\n",
    "\n",
    "# left_should_turn\n",
    "num_positive = np.sum(y_train[:, 3])\n",
    "weight_positive = total_train_sample / (2 * num_positive)  # Divide by 2 for balance\n",
    "weight_negative = total_train_sample / (2 * (total_train_sample - num_positive))\n",
    "left_turn_weight = {0: weight_negative, 1: weight_positive}\n",
    "\n",
    "# right_should_turn\n",
    "num_positive = np.sum(y_train[:, 4])\n",
    "weight_positive = total_train_sample / (2 * num_positive)  # Divide by 2 for balance\n",
    "weight_negative = total_train_sample / (2 * (total_train_sample - num_positive))\n",
    "right_turn_weight = {0: weight_negative, 1: weight_positive}\n",
    "\n",
    "print(left_weight)\n",
    "print(right_weight)\n",
    "print(left_turn_weight)\n",
    "print(right_turn_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (image_size[0], image_size[1], 3)\n",
    "\n",
    "base_model = keras.applications.MobileNetV3Small(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "print(base_model.output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = base_model.output\n",
    "\n",
    "print(feature_extractor.shape)\n",
    "\n",
    "a_model = []\n",
    "\n",
    "output_activation_1 = 'sigmoid'\n",
    "\n",
    "\n",
    "# model 0\n",
    "i = 0\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(128, (3, 3), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_2')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_2')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_2')(a)\n",
    "a = layers.Conv2D(64, (3, 3), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "a = layers.Dense(128, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(86, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.3, name=f'a{i}_dropout')(a)\n",
    "\n",
    "# Branch 1: Angle (regression, 0 to 1)\n",
    "angle_output = layers.Dense(1, activation='sigmoid', name='angle')(a)\n",
    "\n",
    "# Branch 2: Left Arrow (binary)\n",
    "left_arrow_output = layers.Dense(1, activation='sigmoid', name='left_arrow')(a)\n",
    "\n",
    "# Branch 3: Right Arrow (binary)\n",
    "right_arrow_output = layers.Dense(1, activation='sigmoid', name='right_arrow')(a)\n",
    "\n",
    "# Branch 2: Left Arrow (binary)\n",
    "left_arrow_turn_output = layers.Dense(1, activation='sigmoid', name='left_arrow_turn')(a)\n",
    "\n",
    "# Branch 3: Right Arrow (binary)\n",
    "right_arrow_turn_output = layers.Dense(1, activation='sigmoid', name='right_arrow_turn')(a)\n",
    "\n",
    "a_model.append(a)\n",
    "\n",
    "\n",
    "\n",
    "# outputs_dict = {}\n",
    "# loss_dict = {}\n",
    "# metrics_dict = {}\n",
    "\n",
    "# for i in range(len(a_model)):\n",
    "#     outputs_dict[f'angle{i}_output'] = a_model[i]\n",
    "#     loss_dict[f'angle{i}_output'] = 'mse'\n",
    "#     metrics_dict[f'angle{i}_output'] = ['mae']\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs={\n",
    "  \"angle\": angle_output,\n",
    "  \"left_arrow\": left_arrow_output,\n",
    "  \"right_arrow\": right_arrow_output,\n",
    "  \"left_arrow_turn\": left_arrow_turn_output,\n",
    "  \"right_arrow_turn\": right_arrow_turn_output\n",
    "}, name=\"angle_model\")\n",
    "\n",
    "learning_rate = 0.0010\n",
    "\n",
    "losses = {\n",
    "    'angle': 'mean_squared_error',\n",
    "    'left_arrow': WeightedBinaryCrossEntropy(left_weight),\n",
    "    'right_arrow': WeightedBinaryCrossEntropy(right_weight),\n",
    "    'left_arrow_turn': WeightedBinaryCrossEntropy(left_turn_weight),\n",
    "    'right_arrow_turn': WeightedBinaryCrossEntropy(right_turn_weight),\n",
    "}\n",
    "\n",
    "loss_weights = {\n",
    "    'angle': 4.0,  # Higher weight to prioritize regression\n",
    "    'left_arrow': 2.0,\n",
    "    'right_arrow': 2.0,\n",
    "    'left_arrow_turn': 1.0,\n",
    "    'right_arrow_turn': 1.0,\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    'angle': 'mse',\n",
    "    'left_arrow': BalancedAccuracyMetrics.binary_balanced_accuracy,\n",
    "    'right_arrow': BalancedAccuracyMetrics.binary_balanced_accuracy,\n",
    "    'left_arrow_turn': BalancedAccuracyMetrics.binary_balanced_accuracy,\n",
    "    'right_arrow_turn': BalancedAccuracyMetrics.binary_balanced_accuracy,\n",
    "}\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=losses,\n",
    "    loss_weights=loss_weights,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_model = Model(inputs=feature_extractor, outputs=outputs_dict, \n",
    "#                                                     name=\"my_model\")\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,  # Show input/output shapes\n",
    "    show_layer_names=True,  # Show layer names (e.g., \"angle_hidden_2\")\n",
    "    expand_nested=False,  # Keep it flat (no base_model nesting)\n",
    "    show_layer_activations=True,\n",
    "    dpi=96,  # Image resolution\n",
    ")\n",
    "\n",
    "print(\"Saved model image: model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_EPOCHS = 50\n",
    "UNFREEZE_EPOCH = 40\n",
    "\n",
    "current_epoch = 1\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f\"checkpoints/model_epoch_{current_epoch:02d}.keras\",\n",
    "    save_weights_only=False,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_callback = keras.callbacks.History()\n",
    "\n",
    "# Use this lr_schedule when re-gen data every epoch\n",
    "def lr_schedule(epoch, lr):\n",
    "    FIRST_N_EPOCHS = 2\n",
    "    epoch = current_epoch - 1\n",
    "    initial_lr = learning_rate\n",
    "    if epoch < FIRST_N_EPOCHS:\n",
    "        # return 0.002\n",
    "        return max(initial_lr * 2, 0.002)\n",
    "    # elif epoch > 46:\n",
    "    #     return 0.0001\n",
    "    decay = 0.5\n",
    "    return initial_lr / (1 + ((epoch - FIRST_N_EPOCHS) // 3) * decay)\n",
    "    # return max(initial_lr / (1 + ((epoch-FIRST_N_EPOCHS) // 3) * decay), 0.0001)\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule, verbose=1)\n",
    "\n",
    "try:\n",
    "    for i in range(NUM_OF_EPOCHS):\n",
    "        print(f\"\\n{50*'*'}\\nCurrent epoch: {current_epoch}\", end=\"\")\n",
    "\n",
    "        if i == UNFREEZE_EPOCH:\n",
    "            for layer in base_model.layers[:-6]:\n",
    "                layer.trainable = True\n",
    "       \n",
    "        checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "            filepath=f\"checkpoints/model_epoch_{current_epoch:02d}.keras\",\n",
    "            save_weights_only=False,\n",
    "            save_freq=\"epoch\",\n",
    "            verbose=1,\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=1,\n",
    "            steps_per_epoch= train_ds_length // batch_size,\n",
    "            validation_steps= val_ds_length // batch_size,\n",
    "            callbacks=[checkpoint, history_callback, lr_scheduler],\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        current_epoch += 1\n",
    "\n",
    "\n",
    "    # history = model.fit(\n",
    "    #     train_ds,\n",
    "    #     validation_data=val_ds,\n",
    "    #     epochs=NUM_OF_EPOCHS,\n",
    "    #     steps_per_epoch= train_ds_length // batch_size,\n",
    "    #     validation_steps= val_ds_length // batch_size,\n",
    "    #     callbacks=[checkpoint, history_callback, lr_scheduler],\n",
    "    #     verbose=1,\n",
    "    # )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped early—saving history\")\n",
    "    with open(\"training_history.pkl\", \"wb\") as f:\n",
    "        pickle.dump(history_callback.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = history_callback.history\n",
    "# mse_dict = {}\n",
    "# for key in temp.keys():\n",
    "#   if key.endswith(\"loss\"):\n",
    "#     # print(f\"{key}: {temp[key][-1]}\")\n",
    "#     mse_dict[key] = temp[key][-1]\n",
    "\n",
    "# for i in range(int(len(mse_dict)/2)):\n",
    "#   for key in mse_dict.keys():\n",
    "#     if str(i) in key:\n",
    "#       print(f\"{key:20s}: {mse_dict[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")  # Format: YYYYMMDD_HHMM\n",
    "name_template = f'angle_model_{timestamp}'\n",
    "\n",
    "folder_path = f\"Models/{name_template}\"\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "filename = f\"{folder_path}/{name_template}.keras\"\n",
    "model.save(filename)\n",
    "filename = f\"{folder_path}/{name_template}.weights.h5\"\n",
    "model.save_weights(filename)\n",
    "\n",
    "history = history_callback.history\n",
    "\n",
    "filename = f\"{folder_path}/{name_template}_history.pkl\"\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history_callback.history\n",
    "\n",
    "wanted = [\n",
    "    \"angle_loss\",\n",
    "    \"left_arrow_binary_balanced_accuracy\",\n",
    "    \"right_arrow_binary_balanced_accuracy\",\n",
    "    \"left_arrow_turn_binary_balanced_accuracy\",\n",
    "    \"right_arrow_turn_binary_balanced_accuracy\",\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12, 9))\n",
    "\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    if i > len(wanted) - 1:\n",
    "        break\n",
    "    # print(wanted[i])\n",
    "    for key in history.keys():\n",
    "        if key.endswith(wanted[i]):\n",
    "            legend = \"training\"\n",
    "            if \"val\" in key:\n",
    "                legend = \"validation\"\n",
    "            ax[i].plot(history[key], label=legend)\n",
    "            ax[i].set_title(wanted[i])\n",
    "            ax[i].legend()\n",
    "            ax[i].minorticks_on()\n",
    "            ax[i].grid(True, axis=\"y\")\n",
    "            ax[i].grid(which=\"minor\", linestyle=\"--\", linewidth=0.5, color=\"lightgray\")\n",
    "            ax[i].axvline(x=UNFREEZE_EPOCH, color='cyan', linestyle='--')\n",
    "\n",
    "ax[0].set_ylim(0, 0.015)\n",
    "ax[1].set_ylim(0.96, 1)\n",
    "ax[2].set_ylim(0.96, 1)\n",
    "ax[3].set_ylim(0.85, 1)\n",
    "ax[4].set_ylim(0.85, 1)\n",
    "\n",
    "fig.savefig(f\"{folder_path}/{name_template}_performance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val_path, y_val))\n",
    "val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(scale_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(resize_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(rephrase_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = configure_for_performance(val_ds, shuffle=False, batch=False)\n",
    "\n",
    "preds = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(\n",
    "    [\n",
    "        preds[\"angle\"][:, 0].T,\n",
    "        (preds[\"left_arrow\"][:, 0].T > 0.5).astype(int),\n",
    "        (preds[\"right_arrow\"][:, 0].T > 0.5).astype(int),\n",
    "        (preds[\"left_arrow_turn\"][:, 0].T > 0.5).astype(int),\n",
    "        (preds[\"right_arrow_turn\"][:, 0].T > 0.5).astype(int),\n",
    "    ]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 6, figsize=(20, 12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "image_count = 0\n",
    "\n",
    "i = 1\n",
    "print(np.sum(pred[:, i] != y_val[:, i]), np.sum(pred[:, i] == y_val[:, i]), np.sum(pred[:, i] == 1), np.sum(y_val[:, i] == 1))\n",
    "\n",
    "try:\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i][1] != y_val[i][1]:\n",
    "            image = Image.open(X_val_path[i])\n",
    "            ax[image_count].imshow(image)\n",
    "            ax[image_count].set_title(f\"Pred: {np.round(pred[i], 3)}\\nTrue: {y_val[i]}\")\n",
    "            ax[image_count].axis(\"off\")\n",
    "            image_count += 1\n",
    "            # print(f\"{i}: {pred[i]} | {true_val[i]}\")\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 6, figsize=(20, 12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "image_count = 0\n",
    "\n",
    "i = 2\n",
    "print(np.sum(pred[:, i] != y_val[:, i]), np.sum(pred[:, i] == y_val[:, i]), np.sum(pred[:, i] == 1), np.sum(y_val[:, i] == 1))\n",
    "\n",
    "try: \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i][2] != y_val[i][2]:\n",
    "            image = Image.open(X_val_path[i])\n",
    "            ax[image_count].imshow(image)\n",
    "            ax[image_count].set_title(f\"Pred: {np.round(pred[i], 3)}\\nTrue: {y_val[i]}\")\n",
    "            ax[image_count].axis(\"off\")\n",
    "            image_count += 1\n",
    "            # print(f\"{i}: {pred[i]} | {true_val[i]}\")\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 6, figsize=(20, 12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "image_count = 0\n",
    "\n",
    "pred_left_real_right = 0\n",
    "pred_right_real_left = 0\n",
    "\n",
    "i = 2\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if ((pred[i][1] == 1) and (y_val[i][2] == 1)) or ((pred[i][2] == 1) and (y_val[i][1] == 1)):\n",
    "        if (pred[i][2] == 1) and (y_val[i][1] == 1):\n",
    "            pred_right_real_left += 1\n",
    "        elif (pred[i][1] == 1) and (y_val[i][2] == 1):\n",
    "            pred_left_real_right += 1\n",
    "        try: \n",
    "            image = Image.open(X_val_path[i])\n",
    "            ax[image_count].imshow(image)\n",
    "            ax[image_count].set_title(f\"Pred: {np.round(pred[i], 3)}\\nTrue: {y_val[i]}\")\n",
    "            ax[image_count].axis(\"off\")\n",
    "            image_count += 1\n",
    "            # print(f\"{i}: {pred[i]} | {true_val[i]}\")\n",
    "        except IndexError:\n",
    "            pass\n",
    "print(f\"pred_left_real_right: {pred_left_real_right}\", f\"pred_right_real_left: {pred_right_real_left}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RAW MSE: {np.mean(np.square(pred[:, 0] - y_val[:, 0]))}\")\n",
    "\n",
    "diff_dict = {}\n",
    "\n",
    "for key in np.unique(y_val):\n",
    "    diff_dict[key] = []\n",
    "\n",
    "for i in range(len(y_val)):\n",
    "    diff_dict[y_val[i][0]].append((pred[i][0] - y_val[i][0]))\n",
    "\n",
    "# Flatten the dictionary into two lists\n",
    "x_labels = []  # Categories (keys)\n",
    "y_values = []  # Values (list elements)\n",
    "\n",
    "for key, values in diff_dict.items():\n",
    "    x_labels.extend([key] * len(values))\n",
    "    y_values.extend(values)\n",
    "\n",
    "# Create the violin plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x=x_labels, y=y_values)\n",
    "plt.axhline(y=0, linestyle='--', color='gray', linewidth=0.5)\n",
    "ii = 0\n",
    "while ii < 1:\n",
    "    plt.axhline(y=ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "    plt.axhline(y=-ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "    ii += 0.0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_dir = \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/Dataset/machine-learning-in-science-ii-2025\"\n",
    "# training_data_dir = os.path.join(dataset_dir, \"training_data\", \"training_data\")\n",
    "# csv_path = os.path.join(dataset_dir, \"training_norm.csv\")\n",
    "\n",
    "# csv_df = pd.read_csv(csv_path, index_col=\"image_id\")\n",
    "# csv_df.loc[csv_df[\"speed\"] > 1, \"speed\"] = 1\n",
    "# csv_df.drop(columns=[\"speed\"], inplace=True)\n",
    "\n",
    "# X = np.array(csv_df.index)\n",
    "# y = np.array(csv_df[\"angle\"])\n",
    "\n",
    "# _, X_val_provided, _, y_val_provided = train_test_split(\n",
    "#     X, y, test_size=0.2\n",
    "# )\n",
    "\n",
    "# X_val_provided_path = [\n",
    "#     os.path.join(training_data_dir, str(image_id) + \".png\") for image_id in X_val_provided\n",
    "# ]\n",
    "\n",
    "# val_ds = tf.data.Dataset.from_tensor_slices((X_val_provided_path, y_val_provided))\n",
    "# val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# val_ds = val_ds.map(scale_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# val_ds = val_ds.map(resize_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# # val_ds = val_ds.map(rephrase_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# val_ds = configure_for_performance(val_ds, shuffle=False, batch=False)\n",
    "\n",
    "# pred_provided = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_provided\n",
    "angle_pred = pred_provided['angle'][:, 0]\n",
    "np.mean((angle_pred - y_val_provided)**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_dict = {}\n",
    "\n",
    "for key in np.unique(y_val_provided):\n",
    "    diff_dict[key] = []\n",
    "\n",
    "for i in range(len(y_val_provided)):\n",
    "    diff_dict[y_val_provided[i]].append((angle_pred[i] - y_val_provided[i]))\n",
    "\n",
    "# Flatten the dictionary into two lists\n",
    "x_labels = []  # Categories (keys)\n",
    "y_values = []  # Values (list elements)\n",
    "\n",
    "for key, values in diff_dict.items():\n",
    "    x_labels.extend([key] * len(values))\n",
    "    y_values.extend(values)\n",
    "\n",
    "# Create the violin plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x=x_labels, y=y_values)\n",
    "plt.axhline(y=0, linestyle='--', color='gray', linewidth=0.5)\n",
    "ii = 0\n",
    "while ii < 1:\n",
    "    plt.axhline(y=ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "    plt.axhline(y=-ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "    ii += 0.0625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for key in pred.keys():\n",
    "    print(key, end=\", \")\n",
    "    temp = (pred[key][:, 0])\n",
    "    y_pred.append(temp)\n",
    "\n",
    "y_pred_mean = np.mean(y_pred, axis=0)\n",
    "\n",
    "y_pred.append(y_pred_mean)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "y_pred = np.where(np.abs(y_pred - 0.5) < 0.1, y_pred, (y_pred - 0.5) * 1.1 + 0.5)\n",
    "\n",
    "y_pred_ae = y_pred - y_val\n",
    "\n",
    "diff_dict_list = []\n",
    "for i in range(len(y_pred)):\n",
    "    diff_dict = {}\n",
    "\n",
    "    for key in np.unique(y_val):\n",
    "        diff_dict[key] = []\n",
    "\n",
    "    for y_true, y_error in zip(y_val, np.array(y_pred_ae[i, :])):\n",
    "        diff_dict[y_true].append(y_error)\n",
    "\n",
    "    diff_dict_list.append(diff_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    (group_idx, k, v) \n",
    "    for group_idx, diff_dict in enumerate(diff_dict_list) \n",
    "    for k, vals in diff_dict.items() \n",
    "    for v in vals\n",
    "], columns=['Group', 'Key', 'Value'])\n",
    "\n",
    "\n",
    "ranges = [\n",
    "    (float('-inf'), 0.25, 'Keys < 0.25'),\n",
    "    (0.25, 0.5, '0.25 <= Keys < 0.5'),\n",
    "    (0.5, 0.75, '0.5 <= Keys < 0.75'),\n",
    "    (0.75, float('inf'), 'Keys >= 0.75')\n",
    "]\n",
    "\n",
    "# Create figure with 4 subplots\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 12), sharey=True)\n",
    "\n",
    "# Loop over ranges and plot\n",
    "for i, (lower, upper, title) in enumerate(ranges):\n",
    "    # Filter DataFrame for this range\n",
    "    df_subset = df[(df['Key'] >= lower) & (df['Key'] < upper)]\n",
    "    \n",
    "    # Plot violin\n",
    "    sns.violinplot(x='Key', y='Value', hue='Group', data=df_subset, ax=axes[i], \n",
    "                   palette='muted', linewidth=0.7)\n",
    "    \n",
    "    # Customize\n",
    "    axes[i].set_ylim(-0.5, 0.5)\n",
    "    axes[i].set_xlabel('Key')\n",
    "    axes[i].set_ylabel('Value')\n",
    "    axes[i].axhline(y=0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    ii = 0\n",
    "    while ii < 0.5:\n",
    "        axes[i].axhline(y=ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "        axes[i].axhline(y=-ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "        ii += 0.0625\n",
    "    # Make legend horizontal\n",
    "    axes[i].legend(loc='upper center', ncol=len(df['Group'].unique()), \n",
    "                   bbox_to_anchor=(0.5, 1.15), frameon=False)\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig(f\"{folder_path}/{name_template}_distribution.png\")\n",
    "\n",
    "print(np.mean((y_pred[-1]-y_val)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train_tensor))\n",
    "train_ds = train_ds.map(image_id_to_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.map(scale_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.map(rephrase_ds, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = configure_for_performance(train_ds, shuffle=False, batch=False)\n",
    "\n",
    "train_pred = model.predict(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for key in train_pred.keys():\n",
    "    print(key, end=\", \")\n",
    "    temp = (train_pred[key][:, 0])\n",
    "    y_pred.append(temp)\n",
    "\n",
    "y_pred_mean = np.mean(y_pred, axis=0)\n",
    "\n",
    "y_pred.append(y_pred_mean)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# y_pred = np.clip(y_pred, 0, 1)\n",
    "\n",
    "# y_pred = y_pred + np.sign(y_pred - 0.5) * abs(y_pred - 0.5) * 0.3\n",
    "\n",
    "y_pred_ae = y_pred - y_train\n",
    "\n",
    "diff_dict_list = []\n",
    "for i in range(len(y_pred)):\n",
    "    diff_dict = {}\n",
    "\n",
    "    for key in np.unique(y_train):\n",
    "        diff_dict[key] = []\n",
    "\n",
    "    for y_true, y_error in zip(y_train, np.array(y_pred_ae[i, :])):\n",
    "        diff_dict[y_true].append(y_error)\n",
    "\n",
    "    diff_dict_list.append(diff_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    (group_idx, k, v) \n",
    "    for group_idx, diff_dict in enumerate(diff_dict_list) \n",
    "    for k, vals in diff_dict.items() \n",
    "    for v in vals\n",
    "], columns=['Group', 'Key', 'Value'])\n",
    "\n",
    "\n",
    "ranges = [\n",
    "    (float('-inf'), 0.25, 'Keys < 0.25'),\n",
    "    (0.25, 0.5, '0.25 <= Keys < 0.5'),\n",
    "    (0.5, 0.75, '0.5 <= Keys < 0.75'),\n",
    "    (0.75, float('inf'), 'Keys >= 0.75')\n",
    "]\n",
    "\n",
    "# Create figure with 4 subplots\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 12), sharey=True)\n",
    "\n",
    "# Loop over ranges and plot\n",
    "for i, (lower, upper, title) in enumerate(ranges):\n",
    "    # Filter DataFrame for this range\n",
    "    df_subset = df[(df['Key'] >= lower) & (df['Key'] < upper)]\n",
    "    \n",
    "    # Plot violin\n",
    "    sns.violinplot(x='Key', y='Value', hue='Group', data=df_subset, ax=axes[i], \n",
    "                   palette='muted', linewidth=0.7)\n",
    "    \n",
    "    # Customize\n",
    "    axes[i].set_ylim(-0.5, 0.5)\n",
    "    axes[i].set_xlabel('Key')\n",
    "    axes[i].set_ylabel('Value')\n",
    "    axes[i].axhline(y=0, linestyle='--', color='gray', linewidth=0.5)\n",
    "    ii = 0\n",
    "    while ii < 0.5:\n",
    "        axes[i].axhline(y=ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "        axes[i].axhline(y=-ii, linestyle='--', color='gray', linewidth=0.3)\n",
    "        ii += 0.0625\n",
    "    # Make legend horizontal\n",
    "    axes[i].legend(loc='upper center', ncol=len(df['Group'].unique()), \n",
    "                   bbox_to_anchor=(0.5, 1.15), frameon=False)\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig(f\"{folder_path}/{name_template}_train_distribution.png\")\n",
    "\n",
    "print(np.mean((y_pred[-1]-y_train)**2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
