{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd.__version__: 2.2.3\n",
      "tf.__version__: 2.15.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, Model\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"pd.__version__: {pd.__version__}\")\n",
    "print(f\"tf.__version__: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_heads = []\n",
    "arrow_heads = []\n",
    "arrow_turn_heads = []\n",
    "angle_heads = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 200, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/dummy_models/150x200.weights.h5\"\n",
    "\n",
    "size_int_list = np.array(weight_path.split('/')[-1].split('.')[0].split('x')).astype(int)\n",
    "image_shape = (size_int_list[0], size_int_list[1], 3)\n",
    "\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_models = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "mobilenetv3 = keras.applications.MobileNetV3Small(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "\n",
    "backbone = Model(inputs=mobilenetv3.input, outputs=mobilenetv3.layers[-6].output, name=\"MobileNetV3Small_backbone\")\n",
    "neck = Model(inputs=mobilenetv3.layers[-6].output, outputs=mobilenetv3.output, name=\"MobileNetV3Small_neck\")\n",
    "neck_out = neck(backbone.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arrow model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 7, 576)\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.MobileNetV3Small(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=image_shape,\n",
    "    pooling=None,\n",
    "    include_preprocessing=False, \n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "feature_extractor = base_model.output\n",
    "\n",
    "print(feature_extractor.shape)\n",
    "\n",
    "a_model = []\n",
    "\n",
    "output_activation_1 = 'sigmoid'\n",
    "\n",
    "\n",
    "# model 0\n",
    "i = 0\n",
    "\n",
    "a = feature_extractor\n",
    "a = layers.Conv2D(384, (3, 3), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_2')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_2')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_2')(a)\n",
    "a = layers.Conv2D(128, (3, 3), padding='same', \n",
    "                  kernel_initializer='he_uniform', name=f'a{i}_conv_1')(feature_extractor)\n",
    "a = layers.BatchNormalization(name=f'a{i}_bn_1')(a)\n",
    "a = layers.Activation('relu', name=f'a{i}_relu_1')(a)\n",
    "a = layers.GlobalAveragePooling2D(name=f'a{i}_GAP')(a)\n",
    "a = layers.Dense(96, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_2')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout_2')(a)\n",
    "a = layers.Dense(64, activation='relu', kernel_initializer='he_uniform', name=f'a{i}_dense_1')(a)\n",
    "a = layers.Dropout(0.5, name=f'a{i}_dropout')(a)\n",
    "\n",
    "# Branch 1: No arrow (regression, 0 to 1)\n",
    "arrow_output = layers.Dense(3, activation=\"softmax\", name='no_arrow_output')(a)\n",
    "\n",
    "\n",
    "arrow_model = Model(inputs=base_model.input, outputs={\n",
    "  \"arrow\": arrow_output,\n",
    "}, name=\"arrow_model\")\n",
    "\n",
    "\n",
    "arrow_model.load_weights(weight_path)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_of_models):\n",
    "    arrow_heads.append(Model(inputs=base_model.layers[-6].output, outputs=arrow_model.output, name=f\"arrow_head_{len(arrow_heads)}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_0')>},\n",
       " {'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_1')>},\n",
       " {'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_2')>},\n",
       " {'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_3')>},\n",
       " {'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_4')>},\n",
       " {'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_5')>},\n",
       " {'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_6')>},\n",
       " {'arrow': <KerasTensor: shape=(None, 3) dtype=float32 (created by layer 'arrow_head_7')>}]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrow_heads_out = [arrow_head(backbone.output) for arrow_head in arrow_heads]\n",
    "arrow_heads_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = Model(inputs=backbone.input, outputs= arrow_heads_out, name=\"merged_model\")\n",
    "# merged_model = Model(inputs=backbone.input, outputs=[angle_head(backbone.output)] + speed_heads_out, name=\"merged_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(\n",
    "#     merged_model,\n",
    "#     show_shapes=True,  # Show input/output shapes\n",
    "#     show_layer_names=True,  # Show layer names (e.g., \"angle_hidden_2\")\n",
    "#     expand_nested=False,  # Keep it flat (no base_model nesting)\n",
    "#     show_layer_activations=True,\n",
    "#     dpi=96,  # Image resolution\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model into TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjeqf0ulc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpjeqf0ulc/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite model: merged_model_150x200.tflite saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 16:57:51.990400: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-03-21 16:57:51.990458: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-03-21 16:57:51.990661: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpjeqf0ulc\n",
      "2025-03-21 16:57:52.024716: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-03-21 16:57:52.024767: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpjeqf0ulc\n",
      "2025-03-21 16:57:52.114455: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-03-21 16:57:52.482061: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpjeqf0ulc\n",
      "2025-03-21 16:57:52.700923: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 710262 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 67, Total Ops 232, % non-converted = 28.88 %\n",
      " * 67 ARITH ops\n",
      "\n",
      "- arith.constant:   67 occurrences  (f32: 62, i32: 5)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 6)\n",
      "  (f32: 42)\n",
      "  (f32: 11)\n",
      "  (f32: 3)\n",
      "  (f32: 18)\n",
      "  (f32: 10)\n",
      "  (f32: 18)\n",
      "\n",
      "  (f32: 4)\n",
      "  (uq_8: 48)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(merged_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Enable optimization\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tf_lite_file_name = f\"merged_model_{image_shape[0]}x{image_shape[1]}.tflite\"\n",
    "\n",
    "with open(tf_lite_file_name, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"TFLite model: merged_model_{image_shape[0]}x{image_shape[1]}.tflite saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.lite as tflite  # Use this if full TensorFlow is installed\n",
    "# If using tflite-runtime, import this instead:\n",
    "# import tflite_runtime.interpreter as tflite\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tflite.Interpreter(model_path=tf_lite_file_name)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Create a dummy input (modify based on model input shape)\n",
    "input_data = \"/mnt/c/Users/psamt/OneDrive - The University of Nottingham/_Spring/PHYS4036_Machine Learning in Science Part II/Project/Dataset/machine-learning-in-science-ii-2025/test_data/test_data/1.png\"\n",
    "input_data = np.array(Image.open(input_data).convert('RGB').resize((image_shape[1], image_shape[0])))\n",
    "\n",
    "# convert to range(-1, 1)\n",
    "input_data = input_data / 255 * 2 - 1\n",
    "\n",
    "input_data = input_data.astype(np.float32)\n",
    "\n",
    "input_data = np.expand_dims(input_data, axis=0)\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_details = interpreter.get_output_details()\n",
    "# output_dict = {o['name']: o['index'] for o in output_details}\n",
    "\n",
    "# angle_outputs = [interpreter.get_tensor(output_dict[f'StatefulPartitionedCall:{i}']) for i in range(10)]\n",
    "# speed_outputs = [interpreter.get_tensor(output_dict[f'StatefulPartitionedCall:{i}']) for i in range(10, 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32),\n",
       " array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32),\n",
       " array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32),\n",
       " array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32),\n",
       " array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32),\n",
       " array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32),\n",
       " array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32),\n",
       " array([[5.285398e-04, 5.722773e-01, 4.271941e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details_sorted = sorted(output_details, key=lambda x: int(x['name'].split(':')[-1]))\n",
    "\n",
    "all_outputs = [interpreter.get_tensor(out['index']) for out in output_details_sorted]\n",
    "\n",
    "all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_left = int(np.mean(np.squeeze(all_outputs[len(angle_heads):len(angle_heads)+len(arrow_heads)])[:, 1]) > 0.5)\n",
    "arrow_right = int(np.mean(np.squeeze(all_outputs[len(angle_heads):len(angle_heads)+len(arrow_heads)])[:, 2]) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m arrow_turn_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mangle_heads\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marrow_heads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mangle_heads\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marrow_heads\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marrow_turn_heads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      2\u001b[0m arrow_turn_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msqueeze(all_outputs[\u001b[38;5;28mlen\u001b[39m(angle_heads)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrow_heads) : \u001b[38;5;28mlen\u001b[39m(angle_heads)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrow_heads)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrow_turn_heads)])[:, \u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "arrow_turn_left = int(np.mean(np.squeeze(all_outputs[len(angle_heads)+len(arrow_heads) : len(angle_heads)+len(arrow_heads)+len(arrow_turn_heads)])[:, 1]) > 0.5)\n",
    "arrow_turn_right = int(np.mean(np.squeeze(all_outputs[len(angle_heads)+len(arrow_heads) : len(angle_heads)+len(arrow_heads)+len(arrow_turn_heads)])[:, 2]) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7329090237617493"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angle_output = float(np.mean(np.squeeze(all_outputs[0:len(angle_heads)])))\n",
    "\n",
    "# arrow_left = float(np.squeeze(all_outputs[1]))\n",
    "# arrow_right = float(np.squeeze(all_outputs[2]))\n",
    "\n",
    "# arrow_left_turn = float(np.squeeze(all_outputs[3]))\n",
    "# arrow_right_turn = float(np.squeeze(all_outputs[4]))\n",
    "\n",
    "# speed_output = int(np.squeeze(all_outputs[-1])[0] > 0.5)\n",
    "\n",
    "speed_output = int(np.mean(np.squeeze(all_outputs[-5:])[:,0]) > 0.5)\n",
    "\n",
    "# # Split into angle_outputs (0-9) and speed_outputs (10-19)\n",
    "# angle_outputs = np.array(all_outputs[:10])\n",
    "# speed_outputs = np.array(all_outputs[10:])\n",
    "\n",
    "# angle_outputs.mean(), speed_outputs.mean()\n",
    "angle_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arrow_left_turn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(angle_output, arrow_left, arrow_right, \u001b[43marrow_left_turn\u001b[49m, arrow_right_turn, speed_output)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arrow_left_turn' is not defined"
     ]
    }
   ],
   "source": [
    "print(angle_output, arrow_left, arrow_right, arrow_left_turn, arrow_right_turn, speed_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlis2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
